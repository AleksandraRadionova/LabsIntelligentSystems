{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "XLoaGHcnuDqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(input, lexer):\n",
        "    tokens = []\n",
        "    while input:\n",
        "        match = None\n",
        "        for token_type, pattern in lexer.items():\n",
        "            regex = re.compile(pattern)\n",
        "            match = regex.match(input)\n",
        "            if match:\n",
        "                if token_type != \"WHITESPACE\":\n",
        "                    tokens.append((token_type, match.group(0)))\n",
        "                input = input[match.end():]\n",
        "                break\n",
        "        if not match:\n",
        "            raise ValueError(f\"Неожиданный токен: {input[0]}\")\n",
        "    tokens.append((\"EOF\", \"EOF\"))\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "uDyfUIPHuNga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def first(grammar):\n",
        "    first = {nt: set() for nt in grammar}\n",
        "    for nt, rules in grammar.items():\n",
        "        for rule in rules:\n",
        "            if rule[0] not in grammar:\n",
        "                first[nt].add(rule[0])\n",
        "    changed = True\n",
        "    while changed:\n",
        "        changed = False\n",
        "        for nt, rules in grammar.items():\n",
        "            for rule in rules:\n",
        "                before = len(first[nt])\n",
        "                for symbol in rule:\n",
        "                    if symbol in grammar:\n",
        "                        first[nt].update(first[symbol] - {\"EMPTY\"})\n",
        "                        if \"EMPTY\" not in first[symbol]:\n",
        "                            break\n",
        "                    else:\n",
        "                        first[nt].add(symbol)\n",
        "                        break\n",
        "                else:\n",
        "                    first[nt].add(\"EMPTY\")\n",
        "                changed |= len(first[nt]) > before\n",
        "    return first"
      ],
      "metadata": {
        "id": "3vZouGmBuE4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPKmgKLX796i"
      },
      "outputs": [],
      "source": [
        "def follow(grammar, first):\n",
        "    follow = {nt: set() for nt in grammar}\n",
        "    follow[\"commands\"].add(\"EOF\")\n",
        "    changed = True\n",
        "    while changed:\n",
        "        changed = False\n",
        "        for nt, rules in grammar.items():\n",
        "            for rule in rules:\n",
        "                for i, symbol in enumerate(rule):\n",
        "                    if symbol in grammar:\n",
        "                        next_symbols = rule[i + 1:]\n",
        "                        before = len(follow[symbol])\n",
        "                        if next_symbols:\n",
        "                            for s in next_symbols:\n",
        "                                if s in grammar:\n",
        "                                    follow[symbol].update(first[s] - {\"EMPTY\"})\n",
        "                                    if \"EMPTY\" in first[s]:\n",
        "                                        continue\n",
        "                                    break\n",
        "                                else:\n",
        "                                    follow[symbol].add(s)\n",
        "                                    break\n",
        "                        else:\n",
        "                            follow[symbol].update(follow[nt])\n",
        "                        changed |= len(follow[symbol]) > before\n",
        "    return follow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_table(grammar, first, follow):\n",
        "    table = {nt: {} for nt in grammar}\n",
        "    for nt, rules in grammar.items():\n",
        "        for rule in rules:\n",
        "            first_set = set()\n",
        "            for symbol in rule:\n",
        "                if symbol in grammar:\n",
        "                    first_set.update(first[symbol] - {\"EMPTY\"})\n",
        "                    if \"EMPTY\" not in first[symbol]:\n",
        "                        break\n",
        "                else:\n",
        "                    first_set.add(symbol)\n",
        "                    break\n",
        "            else:\n",
        "                first_set.add(\"EMPTY\")\n",
        "            for terminal in first_set - {\"EMPTY\"}:\n",
        "                table[nt][terminal] = rule\n",
        "            if \"EMPTY\" in first_set:\n",
        "                for terminal in follow[nt]:\n",
        "                    table[nt][terminal] = rule\n",
        "    return table"
      ],
      "metadata": {
        "id": "ZLbuBdhFuQ1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse(tokens, grammar, table):\n",
        "    stack = [\"commands\"]\n",
        "    i = 0\n",
        "    while stack:\n",
        "        top = stack.pop()\n",
        "        token_type, token_value = tokens[i]\n",
        "        if top == token_type:\n",
        "            i += 1\n",
        "        elif top in grammar:\n",
        "            rule = table[top].get(token_type)\n",
        "            if not rule:\n",
        "                raise ValueError(f\"Неожиданный токен {token_type} на позиции {i}\")\n",
        "            stack.extend(reversed(rule))\n",
        "        elif top == \"EMPTY\":\n",
        "            continue\n",
        "        else:\n",
        "            raise ValueError(f\"Неожиданный токен {token_type}\")\n",
        "    if i < len(tokens) - 1:\n",
        "        raise ValueError(\"Входные данные, рассмотрены не полностью\")"
      ],
      "metadata": {
        "id": "kAmbGLb7uS6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lexer = {\n",
        "    \"OBJECT\": r\"object\",\n",
        "    \"START\": r\"start\",\n",
        "    \"FORWARD\": r\"forward\",\n",
        "    \"ROTATE\": r\"rotate\",\n",
        "    \"NUMBER\": r\"[0-9]+\",\n",
        "    \"WHITESPACE\": r\"\\s+\",\n",
        "}\n",
        "\n",
        "grammar = {\n",
        "    \"commands\": [[\"command\", \"list_commands\"]],\n",
        "    \"list_commands\": [[\"command\", \"list_commands\"], [\"EMPTY\"]],\n",
        "    \"command\": [[\"OBJECT\", \"list_command\"]],\n",
        "    \"list_command\": [[\"moveCommand\"], [\"rotateCommand\"], [\"startCommand\"]],\n",
        "    \"moveCommand\": [[\"FORWARD\", \"NUMBER\"]],\n",
        "    \"rotateCommand\": [[\"ROTATE\", \"NUMBER\"]],\n",
        "    \"startCommand\": [[\"START\"]],\n",
        "}\n",
        "\n",
        "input_text = \"object start object rotate 45 object forward 10\"\n",
        "tokens = tokenize(input_text, lexer)\n",
        "\n",
        "first = first(grammar)\n",
        "follow = follow(grammar, first)\n",
        "table = create_table(grammar, first, follow)\n",
        "\n",
        "try:\n",
        "    parse(tokens, grammar, table)\n",
        "    print(\"Входные данные соответствуют грамматике\")\n",
        "except ValueError as e:\n",
        "    print(f\"Ошибка: {e}\")"
      ],
      "metadata": {
        "id": "irM3jLj_8PNZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd3a8367-02f4-4601-96b7-55d30aae9530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входные данные соответствуют грамматике\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1XarpowK9qOV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}